{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5 -0.5 -1.5 ...  0.5 -2.5 -2.5]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1535,2) and (1,1535) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=99'>100</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([data[\u001b[39m\"\u001b[39m\u001b[39mHouse val\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=100'>101</a>\u001b[0m log_model \u001b[39m=\u001b[39m Logistic()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=101'>102</a>\u001b[0m log_model\u001b[39m.\u001b[39;49mfit(X, y, w)\n",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36mLogistic.fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=83'>84</a>\u001b[0m     min_loss \u001b[39m=\u001b[39m new_loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=84'>85</a>\u001b[0m     new_weights \u001b[39m=\u001b[39m w\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=85'>86</a>\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_weights(X, y, w, new_loss)\n",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36mLogistic.update_weights\u001b[1;34m(self, X, y, weights_old, loss)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=65'>66</a>\u001b[0m sigm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sigmoid_function(z)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(sigm \u001b[39m-\u001b[39m y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=67'>68</a>\u001b[0m gradient \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(X\u001b[39m.\u001b[39;49mT, (sigm \u001b[39m-\u001b[39;49m y)) \u001b[39m/\u001b[39m m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=68'>69</a>\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=69'>70</a>\u001b[0m \u001b[39m# sigm = 1 / (1 + np.exp(-(X.dot(w))))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=70'>71</a>\u001b[0m \u001b[39m# print(X.T.shape,  (sigm - y).shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=71'>72</a>\u001b[0m \u001b[39m# print(weights_old.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=72'>73</a>\u001b[0m \u001b[39m# print(weights_old.shape, X.shape, (sigm - y).T.shape)\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1535,2) and (1,1535) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "    del_cols = set()\n",
    "    save_labels = ['Hogwarts House', \"Astronomy\", \"Herbology\"]\n",
    "    with open(\"dataset_train.csv\") as file:\n",
    "        rows_list = file.read().splitlines()\n",
    "        col_dict = {}\n",
    "        labels = rows_list[0].split(',')\n",
    "        for label in labels:\n",
    "            col_dict[label] = []\n",
    "            if label not in save_labels:\n",
    "                del_cols.add(label)\n",
    "        for row in rows_list[1:]:\n",
    "            values = row.split(\",\")\n",
    "            for index in range(len(col_dict)):\n",
    "                col_dict[labels[index]].append(values[index])\n",
    "\n",
    "    for key in del_cols:\n",
    "        col_dict.pop(key)\n",
    "    return col_dict\n",
    "\n",
    "def drop_empty_vals(data):\n",
    "    del_rows = set()\n",
    "    del_rows = [ind_val for key, lst in data.items() for ind_val in range(len(lst)) if lst[ind_val] == '']\n",
    "    new_data = {key:[] for key in data.keys()}\n",
    "    for key, lst in data.items():\n",
    "        for ind_val in range(len(lst)):\n",
    "            if ind_val not in del_rows:\n",
    "                new_data[key].append(lst[ind_val])   \n",
    "    return new_data\n",
    "\n",
    "def convert_to_int(col_dict):\n",
    "    for key, list_values in col_dict.items():\n",
    "        col_dict[key] = [int(float(val)) if key!='Hogwarts House' else val for val in list_values]\n",
    "\n",
    "def add_int_col_for_house(data):\n",
    "    data['House val'] = []\n",
    "    houses = set()\n",
    "    for val in data[\"Hogwarts House\"]:\n",
    "        houses.add(val)\n",
    "    houses = list(houses)\n",
    "    order_house = {}\n",
    "    for ind_house in range(len(houses)):\n",
    "        order_house[houses[ind_house]] = ind_house\n",
    "    for ind_house in range(len(data[\"Hogwarts House\"])):\n",
    "        data['House val'].append(order_house[data[\"Hogwarts House\"][ind_house]])\n",
    "    return data\n",
    "\n",
    "class Logistic:\n",
    "    alpha = 0.001\n",
    "\n",
    "    def _sigmoid_function(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, X, y, w):\n",
    "        m = y.size\n",
    "        z = -w.T.dot(X)\n",
    "        matrix_sigm = self._sigmoid_function(z)\n",
    "        # print((-y.T).size, (-y).T, np.ma.log(matrix_sigm).filled(0))\n",
    "        return (1/m) * np.sum(-y.T.dot(np.ma.log(matrix_sigm).filled(0)) - (1 - y).T.dot(np.ma.log(1 - matrix_sigm).filled(0)))\n",
    "\n",
    "    def update_weights(self, X, y, weights_old, loss):\n",
    "        m = y.size\n",
    "        z = -w.T.dot(X)\n",
    "        sigm = self._sigmoid_function(z)\n",
    "        print(sigm - y)\n",
    "        gradient = np.dot(X.T, (sigm - y)) / m\n",
    "        print(X.T)\n",
    "        # sigm = 1 / (1 + np.exp(-(X.dot(w))))\n",
    "        # print(X.T.shape,  (sigm - y).shape)\n",
    "        # print(weights_old.shape)\n",
    "        # print(weights_old.shape, X.shape, (sigm - y).T.shape)\n",
    "        print(weights_old.shape, X.shape, (sigm - y).T.shape)\n",
    "        weights_new = weights_old - (self.alpha * gradient)\n",
    "        return weights_new\n",
    "\n",
    "    def fit(self, X, y, w):\n",
    "        min_loss = self.cost_function(X, y, w)\n",
    "        new_weights = w\n",
    "        for epoch in range(1):\n",
    "            new_loss = self.cost_function(X, y, w)\n",
    "            if min_loss > new_loss:\n",
    "                min_loss = new_loss\n",
    "                new_weights = w\n",
    "            w = self.update_weights(X, y, w, new_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = get_data()\n",
    "data = drop_empty_vals(data)\n",
    "# #it makes sence to change arounding\n",
    "convert_to_int(data)\n",
    "\n",
    "data = add_int_col_for_house(data)\n",
    "X = np.array([data[\"Astronomy\"], data[\"Herbology\"]])\n",
    "w = np.zeros((X.shape[0], 1))\n",
    "# print(X.shape, w.shape)\n",
    "y = np.array([data[\"House val\"]])\n",
    "log_model = Logistic()\n",
    "log_model.fit(X, y, w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1535,1) and (1535,2) not aligned: 1 (dim 1) != 1535 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39m# print(X,w, y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000001?line=10'>11</a>\u001b[0m new_log \u001b[39m=\u001b[39m Logistic()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000001?line=13'>14</a>\u001b[0m new_log\u001b[39m.\u001b[39;49mfit(X, w, y)\n",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36mLogistic.fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, w):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=73'>74</a>\u001b[0m     min_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcost_function(X, y, w)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=74'>75</a>\u001b[0m     new_weights \u001b[39m=\u001b[39m w\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=75'>76</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36mLogistic.cost_function\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcost_function\u001b[39m(\u001b[39mself\u001b[39m, X, y, w):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=56'>57</a>\u001b[0m     m \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39msize\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=57'>58</a>\u001b[0m     matrix_sigm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sigmoid_function(X, w)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=58'>59</a>\u001b[0m     \u001b[39m# print((-y.T).size, (-y).T, np.ma.log(matrix_sigm).filled(0))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=59'>60</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mm) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum((\u001b[39m-\u001b[39my)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mlog(matrix_sigm)\u001b[39m.\u001b[39mfilled(\u001b[39m0\u001b[39m)) \u001b[39m-\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m y)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m matrix_sigm)\u001b[39m.\u001b[39mfilled(\u001b[39m0\u001b[39m)))\n",
      "\u001b[1;32mc:\\Users\\Руслан\\Desktop\\logistical_regression\\logreg_train.ipynb Cell 1'\u001b[0m in \u001b[0;36mLogistic._sigmoid_function\u001b[1;34m(self, X, w)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sigmoid_function\u001b[39m(\u001b[39mself\u001b[39m, X, w):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%A0%D1%83%D1%81%D0%BB%D0%B0%D0%BD/Desktop/logistical_regression/logreg_train.ipynb#ch0000000?line=53'>54</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mw\u001b[39m.\u001b[39;49mT\u001b[39m.\u001b[39;49mdot(X)))\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1535,1) and (1535,2) not aligned: 1 (dim 1) != 1535 (dim 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset_train.csv')\n",
    "df['Herbology'].replace('', np.nan, inplace=True)\n",
    "df['Astronomy'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['Herbology'], inplace=True)\n",
    "df.dropna(subset=['Astronomy'], inplace=True)\n",
    "X = df.loc[:, [\"Astronomy\", \"Herbology\"]].to_numpy()\n",
    "w = np.zeros((X.shape[0], X.shape[1]))\n",
    "# print(X,w, y)\n",
    "new_log = Logistic()\n",
    "\n",
    "\n",
    "new_log.fit(X, w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###deleting duplicates\n",
    "\n",
    "# set_without_duplicates = set()\n",
    "\n",
    "# for ind_val in range(len(col_dict[\"Hogwarts House\"])):\n",
    "#     tupl = (col_dict[\"Hogwarts House\"][ind_val], col_dict[\"Astronomy\"][ind_val], col_dict[\"Herbology\"][ind_val])\n",
    "#     set_without_duplicates.add(tupl)\n",
    "\n",
    "# for label in save_labels:\n",
    "#     col_dict[label] = []\n",
    "\n",
    "# for tup in set_without_duplicates:\n",
    "#     for x in range(3):\n",
    "#         col_dict[save_labels[x]].append(tup[x])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af206512f12a9994cbc74d6126adbf6c507a4bdbf86d6b66f7d459371408485b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
