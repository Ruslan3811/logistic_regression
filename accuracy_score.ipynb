{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.0456026058632%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from math import *\n",
    "\n",
    "def get_data(dataset):\n",
    "    del_cols = set()\n",
    "    save_labels = ['Hogwarts House', \"Astronomy\", \"Herbology\"]\n",
    "    with open(dataset) as file:\n",
    "        rows_list = file.read().splitlines()\n",
    "        col_dict = {}\n",
    "        labels = rows_list[0].split(',')\n",
    "        for label in labels:\n",
    "            col_dict[label] = []\n",
    "            if label not in save_labels:\n",
    "                del_cols.add(label)\n",
    "        for row in rows_list[1:]:\n",
    "            values = row.split(\",\")\n",
    "            for index in range(len(col_dict)):\n",
    "                col_dict[labels[index]].append(values[index])\n",
    "    for key in del_cols:\n",
    "        col_dict.pop(key)\n",
    "    return col_dict\n",
    "\n",
    "def drop_empty_vals(data):\n",
    "    del_rows = set()\n",
    "    tmp_data = {}\n",
    "    tmp_data[\"Herbology\"] = data[\"Herbology\"]\n",
    "    tmp_data[\"Astronomy\"] = data[\"Astronomy\"]\n",
    "    del_rows = [ind_val for key, lst in tmp_data.items() for ind_val in range(len(lst)) if lst[ind_val] == '']\n",
    "    new_data = {key:[] for key in data.keys()}\n",
    "    for key, lst in data.items():\n",
    "        for ind_val in range(len(lst)):\n",
    "            if ind_val not in del_rows:\n",
    "                new_data[key].append(lst[ind_val])\n",
    "    return new_data\n",
    "\n",
    "def convert_to_int(col_dict):\n",
    "    for key, list_values in col_dict.items():\n",
    "        col_dict[key] = [float(val) if key!='Hogwarts House' else val for val in list_values]\n",
    "\n",
    "def add_int_col_for_house(data):\n",
    "    data['House val'] = []\n",
    "    houses = set()\n",
    "    for val in data[\"Hogwarts House\"]:\n",
    "        houses.add(val)\n",
    "    houses = list(houses)\n",
    "    order_house = {}\n",
    "    for ind_house in range(len(houses)):\n",
    "        order_house[houses[ind_house]] = ind_house\n",
    "    for ind_house in range(len(data[\"Hogwarts House\"])):\n",
    "        data['House val'].append(order_house[data[\"Hogwarts House\"][ind_house]])\n",
    "    return data, order_house\n",
    "\n",
    "def mean(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def standart_deviation(np_feature, vals):\n",
    "    return sqrt(np.sum(np.power(np_feature - mean(vals), 2)) / len(vals))\n",
    "\n",
    "def normalize_data(features):\n",
    "    for feature, vals in features.items():\n",
    "        np_feature = np.array(vals)\n",
    "        features[feature] = (np_feature - min(vals)) / (max(vals) - min(vals))\n",
    "    return features\n",
    "\n",
    "def  standartize_data(features):\n",
    "    for feature, vals in features.items():\n",
    "        np_feature = np.array(vals)\n",
    "        features[feature] = (np_feature - mean(vals)) / standart_deviation(np_feature, vals)\n",
    "    return features\n",
    "\n",
    "def convert_int_to_classname(dict_house, y_pred1):\n",
    "    y_pred1 = y_pred1.astype(str)\n",
    "    for key, value in dict_house.items():\n",
    "        y_pred1[y_pred1 == str(value)] = key\n",
    "    return y_pred1\n",
    "\n",
    "class Logistic:\n",
    "    alpha = 0.001\n",
    "\n",
    "    def _sigmoid_function(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, X, y, w):\n",
    "        m = y.size\n",
    "        z = np.dot(w, X.T)\n",
    "        matrix_sigm = self._sigmoid_function(z)\n",
    "        log_sigmoid_1 = np.log(matrix_sigm)\n",
    "        log_sigmoid_2 = np.log(1 - matrix_sigm)\n",
    "        return (-1/m) * np.sum(np.dot((y).T,log_sigmoid_1) + np.dot((1 - y).T, (log_sigmoid_2)))\n",
    "\n",
    "    def update_weights(self, X, y, weights_old):\n",
    "        m = y.size\n",
    "        z = np.dot(weights_old, X.T)\n",
    "        sigm = self._sigmoid_function(z)\n",
    "        gradient = np.dot(X.T, (sigm - y)) / m\n",
    "        weights_new = weights_old - (self.alpha * gradient)\n",
    "        return weights_new\n",
    "\n",
    "    def fit(self, X, y, w, dict_house):\n",
    "        list_w = []\n",
    "        list_losses = []\n",
    "        uniq_y = list(dict_house.values())\n",
    "        \n",
    "        #iterating each class\n",
    "        for class_y in uniq_y:\n",
    "            tmp_y = copy.deepcopy(y)\n",
    "\n",
    "            #replacing value in curr class to 1, other to 0\n",
    "            for ind_class_y in range(len(y)):\n",
    "                if tmp_y[ind_class_y] == class_y:\n",
    "                    tmp_y[ind_class_y] = 1\n",
    "                else:\n",
    "                    tmp_y[ind_class_y] = 0\n",
    "            min_loss = self.cost_function(X, tmp_y, w)\n",
    "            new_loss = self.cost_function(X, tmp_y, w)\n",
    "            norm_weights = copy.deepcopy(w)\n",
    "            new_weights = copy.deepcopy(w)            \n",
    "            # print(class_y, min_loss)\n",
    "\n",
    "            #updating weights\n",
    "            for epoch in range(10000):\n",
    "                # if abs(min_loss) > abs(new_loss):\n",
    "                #     min_loss = copy.deepcopy(new_loss)\n",
    "                #     norm_weights = copy.deepcopy(new_weights)\n",
    "                new_weights = self.update_weights(X, tmp_y, new_weights)\n",
    "                new_loss = self.cost_function(X, tmp_y, new_weights)\n",
    "            list_w.append((new_weights, class_y))\n",
    "            list_losses.append((new_loss, class_y))\n",
    "        return list_w, list_losses\n",
    "\n",
    "    def predict(self, data, X, list_w):\n",
    "        pred_y = []\n",
    "        \n",
    "        # iter each sample for each possible weights(amount different triples of weights = amount of classes)\n",
    "        # ind of max probability is predicted class(realization analogy of argmax)\n",
    "        for ind_row in range(len(data[\"Hogwarts House\"])):\n",
    "            max_prob = None\n",
    "            save_ind = None\n",
    "            X_tmp = copy.deepcopy(X)\n",
    "            for ind_w in range(len(list_w)):\n",
    "                np_w = copy.deepcopy(np.array(list_w))\n",
    "                wX = np.dot(X_tmp[ind_row], np_w[ind_w])\n",
    "                sigm_probability = log_model._sigmoid_function(wX)\n",
    "                if max_prob == None or max_prob < sigm_probability:\n",
    "                    save_ind = ind_w\n",
    "                    max_prob = sigm_probability\n",
    "            pred_y.append(save_ind)\n",
    "        pred_y = np.array(pred_y)\n",
    "        return pred_y\n",
    "\n",
    "    def score(self, data, X, list_w):\n",
    "        y_pred = self.predict(data, X, list_w)\n",
    "        length = len(y_pred)\n",
    "        equals = 0\n",
    "        for ind in range(length):\n",
    "            if y_pred[ind] == y[ind]:\n",
    "                equals += 1\n",
    "        return f\"Accuracy: {equals * 100 / length}%\"\n",
    "\n",
    "def prep_data(dataset):\n",
    "    data = get_data(dataset)\n",
    "    data = drop_empty_vals(data)\n",
    "\n",
    "    data[\"f0\"] = [1 for x in range(len(data[\"Hogwarts House\"]))]\n",
    "\n",
    "    # #it makes sence to change arounding\n",
    "    convert_to_int(data)\n",
    "\n",
    "    data, dict_house = add_int_col_for_house(data)\n",
    "    standartized_data = standartize_data({\"Herbology\": data[\"Herbology\"], \"Astronomy\": data[\"Astronomy\"]})\n",
    "\n",
    "    #matrix\n",
    "    X = np.array([data[\"f0\"], standartized_data[\"Herbology\"], standartized_data[\"Astronomy\"]]).T\n",
    "    return data, dict_house, X\n",
    "\n",
    "def train(data, dict_house, X):\n",
    "    # #вектор\n",
    "    # w = np.random.normal(0, 1, X.shape[1])\n",
    "    w = np.array([-1.56335628, -0.44355203, -0.1269146])\n",
    "    #vector\n",
    "    y = np.array((data[\"House val\"]))\n",
    "\n",
    "    log_model = Logistic()\n",
    "    tuple_w_class, list_losses = log_model.fit(X, y, w, dict_house)\n",
    "\n",
    "    list_w = [w for w, cls in tuple_w_class]\n",
    "    return data, X, list_w, dict_house, log_model, y\n",
    "\n",
    "#tarin\n",
    "if __name__=='__main__':\n",
    "    data, dict_house, X = prep_data(\"dataset_train.csv\")\n",
    "    # print(dict_house)\n",
    "    data, X, list_w, dict_house, log_model, y = train(data, dict_house, X)\n",
    "    y_pred1 = log_model.predict(data, X, list_w)\n",
    "    print(log_model.score(data, X, list_w))\n",
    "    \n",
    "    y_pred1 = convert_int_to_classname(dict_house, y_pred1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#bias\n",
    "#normalization\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "data, dict_house3, X = prep_data(\"dataset_test.csv\")\n",
    "y_pred1 = log_model.predict(data, X, list_w)\n",
    "y_pred1 = convert_int_to_classname(dict_house, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.88114113 -1.01360688]\n",
      " [ 1.         -1.36345085 -1.13690315]\n",
      " [ 1.          1.26393844 -0.77957728]\n",
      " ...\n",
      " [ 1.         -0.8299861   0.96895927]\n",
      " [ 1.          0.4434462   0.79538671]\n",
      " [ 1.          0.82248391  1.24733768]]\n",
      "0.9920424403183024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df2 = pd.read_csv('dataset_train.csv')\n",
    "df2['Herbology'].replace('', np.nan, inplace=True)\n",
    "df2['Astronomy'].replace('', np.nan, inplace=True)\n",
    "df2.dropna(subset=['Herbology'], inplace=True)\n",
    "df2.dropna(subset=['Astronomy'], inplace=True)\n",
    "f0 = [1 for x in range(len(df2['Herbology']))]\n",
    "X2 = np.array(df2.loc[:, [\"Herbology\", \"Astronomy\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X2)\n",
    "X2 = scaler.transform(X2)\n",
    "\n",
    "X2 = np.insert(X2, 0, 1, axis=1)\n",
    "print(X2)\n",
    "y2 = np.array(df2.loc[:, [\"Hogwarts House\"]])\n",
    "y2 = np.ravel(y2, 'C')\n",
    "clf2 = LogisticRegression(max_iter=30000).fit(X2, y2.T)\n",
    "\n",
    "df2 = pd.read_csv('dataset_test.csv')\n",
    "df2['Herbology'].replace('', np.nan, inplace=True)\n",
    "df2['Astronomy'].replace('', np.nan, inplace=True)\n",
    "df2.dropna(subset=['Herbology'], inplace=True)\n",
    "df2.dropna(subset=['Astronomy'], inplace=True)\n",
    "X2 = np.array(df2.loc[:, [\"Herbology\", \"Astronomy\"]])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X2)\n",
    "X2 = scaler.transform(X2)\n",
    "X2 = np.insert(X2, 0, 1, axis=1)\n",
    "\n",
    "y_pred2 = clf2.predict(X2)\n",
    "y = np.array(y)\n",
    "print(accuracy_score(y_pred1, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af206512f12a9994cbc74d6126adbf6c507a4bdbf86d6b66f7d459371408485b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
